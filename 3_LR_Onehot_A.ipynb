{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Onehot_A\" data-toc-modified-id=\"Onehot_A-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Onehot_A</a></span></li><li><span><a href=\"#导入与分割数据\" data-toc-modified-id=\"导入与分割数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>导入与分割数据</a></span></li><li><span><a href=\"#A_cat\" data-toc-modified-id=\"A_cat-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>A_cat</a></span></li><li><span><a href=\"#A_hour\" data-toc-modified-id=\"A_hour-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>A_hour</a></span></li><li><span><a href=\"#A_xgb\" data-toc-modified-id=\"A_xgb-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>A_xgb</a></span></li><li><span><a href=\"#B_cat\" data-toc-modified-id=\"B_cat-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>B_cat</a></span></li><li><span><a href=\"#A_his\" data-toc-modified-id=\"A_his-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>A_his</a></span></li><li><span><a href=\"#结论\" data-toc-modified-id=\"结论-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>结论</a></span></li><li><span><a href=\"#'C':-0.1\" data-toc-modified-id=\"'C':-0.1-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>'C': 0.1</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T04:02:22.860224Z",
     "start_time": "2018-02-23T04:02:01.313502Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# filelist: \n",
    "#         train:40428967,  \n",
    "#     minitrain:4042898,  \n",
    "# miniminitrain:404291,  \n",
    "#    test_click:4577464\n",
    "#  \n",
    "\n",
    "#import os\n",
    "#os.chdir('/media/zhou/0004DD1700005FE8/AI/00/project_2/')\n",
    "#os.chdir('E:/AI/00/project_2')\n",
    "\n",
    "class flags(object):\n",
    "    def __init__(self, file_name, onehot_cat):\n",
    "        self.file_name = file_name\n",
    "        self.onehot_cat = onehot_cat\n",
    "        self.data_dir = '../data/project_2/data/{0}/'.format(self.onehot_cat)\n",
    "        self.output_dir = '../data/project_2/output/{0}/'.format(self.onehot_cat)\n",
    "        self.model_dir = '../data/project_2/models/{0}/'.format(self.onehot_cat)\n",
    "\n",
    "class params(object):\n",
    "    def __init__(self, onehot_name):\n",
    "        self.threshold = 10\n",
    "        self.chunksize = 1e3\n",
    "        self.num_trees = 50\n",
    "        self.deep = 15\n",
    "        self.split = '='\n",
    "        # ['A_cat', 'A_hour', 'A_xgb', \n",
    "        #  'B_cat', 'C_his']\n",
    "        self.onehot_name = onehot_name\n",
    "        self.lr_C = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MergeNpz(output_path, file_name, data_begin, threshold=10, is_click=False):\n",
    "    \"\"\"把生成的多个.npz合并成一个文件并保存\"\"\"\n",
    "    #导入从0开始的文件, 为下面的合并做准备\n",
    "    click_name = 'more'\n",
    "    if is_click: \n",
    "        click_name = 'click'\n",
    "        threshold = ''\n",
    "    \n",
    "    X_train = ss.load_npz(output_path+'{0}_X_{3}{1}_begin{2}.npz'.format(\n",
    "                                file_name, threshold, data_begin[0],click_name))\n",
    "    y_train = ss.load_npz(output_path+'{0}_y_{3}{1}_begin{2}.npz'.format(\n",
    "                                file_name, threshold, data_begin[0],click_name))\n",
    "\n",
    "    for begin in range(1,len(data_begin)): #循环读入文件\n",
    "        #文件暂存\n",
    "        X_train_tmp = ss.load_npz(output_path+'{0}_X_{3}{1}_begin{2}.npz'.format(\n",
    "                                    file_name, threshold, data_begin[begin],click_name))\n",
    "        y_train_tmp = ss.load_npz(output_path+'{0}_y_{3}{1}_begin{2}.npz'.format(\n",
    "                                    file_name, threshold, data_begin[begin],click_name))\n",
    "        X_train = ss.vstack((X_train, X_train_tmp))  #与原有 行稀疏矩阵 进行 行连接\n",
    "        y_train = ss.hstack((y_train, y_train_tmp))  #与原有 列稀疏矩阵 进行 列连接\n",
    "    \n",
    "    print('total shape: ',X_train.shape, ' | ', y_train.shape)\n",
    "    #保存最终连接完成的稀疏矩阵\n",
    "    #ss.save_npz(output_path+'{0}_X_more{1}'.format(file_name, threshold), X_train)\n",
    "    #ss.save_npz(output_path+'{0}_y_more{1}'.format(file_name, threshold), y_train)\n",
    "    #print('saved in {0}'.format(output_path))\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import scipy.sparse as ss\n",
    "#from  sklearn.cross_validation  import  train_test_split \n",
    "#import xgboost as xgb\n",
    "#from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalsize = {'minitrain':4042898, 'test_click':4577464}\n",
    "file_size = totalsize[FLAGS.file_name]  #总的数据量\n",
    "block_size = 100000  #数据块大小\n",
    "\n",
    "#定义参数\n",
    "data_path = FLAGS.data_dir  # + '../data/project_2/'\n",
    "file_name = FLAGS.file_name\n",
    "chunksize = 1000\n",
    "threshold = 10\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "data_begins = [i for i in range(0,file_size,block_size)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import line_profiler\n",
    "import sys\n",
    "\n",
    "\n",
    "def test():\n",
    "    print 'haha'\n",
    "\n",
    "prof = line_profiler.LineProfiler(MergeNpz)\n",
    "prof.enable()  # 开始性能分析\n",
    "a, b = MergeNpz(output_path, file_name, data_begins[:-6], threshold, False)\n",
    "prof.disable()  # 停止性能分析\n",
    "prof.print_stats(sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入与分割数据"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T13:48:51.109670Z",
     "start_time": "2018-02-08T13:48:51.064640Z"
    },
    "scrolled": true
   },
   "source": [
    "# 把生成好的.npz全部合并可以选择部分合并, \n",
    "# 把要合并的begin 放到 list(data_begins)中, \n",
    "# 如[0,200000,900000]做val, [100000,300000, . . . ]做训练, \n",
    "\n",
    "X_train, y_train = MergeNpz(output_path, file_name, data_begins[:-6], threshold, False)\n",
    "X_val, y_val = MergeNpz(output_path, file_name, data_begins[-6:], threshold, False)\n",
    "\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "y_val = y_val.toarray().astype(np.float32)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T13:48:51.109670Z",
     "start_time": "2018-02-08T13:48:51.064640Z"
    },
    "scrolled": true
   },
   "source": [
    "# 把生成好的.npz全部合并可以选择部分合并, \n",
    "# 把要合并的begin 放到 list(data_begins)中, \n",
    "# 如[0,200000,900000]做val, [100000,300000, . . . ]做训练, \n",
    "X_train_click, y_train_click = MergeNpz(output_path, file_name, data_begins[:-6], threshold, True)\n",
    "X_train = ss.hstack((X_train, X_train_click))\n",
    "X_val_click, y_val_click = MergeNpz(output_path, file_name, data_begins[-6:], threshold, True)\n",
    "X_val = ss.hstack((X_val, X_val_click))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_cat')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500000, 646491), (542898, 646491))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "solvers = ['sag','saga']\n",
    "Cs = [ 0.01, 0.1, 1, 10, 100, ]\n",
    "tuned_parameters = dict(solver = solvers, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=3, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 329.47616482,  369.60390115,  324.4078722 ,  367.42991328,\n",
       "         212.2998058 ,  372.03892843,  336.70420321,  382.0876294 ,\n",
       "         336.89638193,  373.32977041]),\n",
       " 'mean_score_time': array([ 1.03666671,  1.0390203 ,  1.03444759,  1.04006028,  1.03586078,\n",
       "         1.03757874,  1.04104495,  1.0464867 ,  1.04656116,  1.04050708]),\n",
       " 'mean_test_score': array([-0.40504352, -0.40502292, -0.40257904, -0.40257576, -0.40604935,\n",
       "        -0.40604334, -0.42796114, -0.42196957, -0.44536789, -0.4290202 ]),\n",
       " 'mean_train_score': array([-0.39785209, -0.39785271, -0.38816782, -0.38816793, -0.36360968,\n",
       "        -0.36365825, -0.3358255 , -0.33998795, -0.3302141 , -0.33608356]),\n",
       " 'param_C': masked_array(data = [0.01 0.01 0.1 0.1 1 1 10 10 100 100],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_solver': masked_array(data = ['sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 0.01, 'solver': 'sag'},\n",
       "  {'C': 0.01, 'solver': 'saga'},\n",
       "  {'C': 0.1, 'solver': 'sag'},\n",
       "  {'C': 0.1, 'solver': 'saga'},\n",
       "  {'C': 1, 'solver': 'sag'},\n",
       "  {'C': 1, 'solver': 'saga'},\n",
       "  {'C': 10, 'solver': 'sag'},\n",
       "  {'C': 10, 'solver': 'saga'},\n",
       "  {'C': 100, 'solver': 'sag'},\n",
       "  {'C': 100, 'solver': 'saga'}],\n",
       " 'rank_test_score': array([ 4,  3,  2,  1,  6,  5,  8,  7, 10,  9], dtype=int32),\n",
       " 'split0_test_score': array([-0.40750919, -0.40745695, -0.40380244, -0.40379774, -0.40655314,\n",
       "        -0.40654822, -0.42744951, -0.42175574, -0.44433048, -0.42855669]),\n",
       " 'split0_train_score': array([-0.39734624, -0.39734696, -0.3879016 , -0.38790172, -0.36365887,\n",
       "        -0.36370867, -0.33607554, -0.34020885, -0.33049805, -0.33633028]),\n",
       " 'split1_test_score': array([-0.40422905, -0.40423207, -0.40181331, -0.40181422, -0.40480042,\n",
       "        -0.40479562, -0.42413399, -0.4189142 , -0.43946491, -0.42512879]),\n",
       " 'split1_train_score': array([-0.39679413, -0.39679487, -0.38680462, -0.38680473, -0.3613926 ,\n",
       "        -0.36144113, -0.33266883, -0.33697196, -0.32686796, -0.3329375 ]),\n",
       " 'split2_test_score': array([-0.40339232, -0.40337973, -0.40212138, -0.40211531, -0.40679449,\n",
       "        -0.40678617, -0.43229991, -0.42523876, -0.45230827, -0.43337512]),\n",
       " 'split2_train_score': array([-0.39941591, -0.3994163 , -0.38979724, -0.38979736, -0.36577757,\n",
       "        -0.36582496, -0.33873214, -0.34278303, -0.33327628, -0.3389829 ]),\n",
       " 'std_fit_time': array([ 1.48730169,  0.35307156,  1.63313849,  4.23725414,  8.35775001,\n",
       "         4.53283893,  5.05367555,  4.26531666,  1.08761522,  0.29341222]),\n",
       " 'std_score_time': array([ 0.00500289,  0.00249675,  0.00152971,  0.0009377 ,  0.00069383,\n",
       "         0.00084042,  0.00274369,  0.00612199,  0.00186383,  0.00230375]),\n",
       " 'std_test_score': array([ 0.00177664,  0.00175594,  0.00087417,  0.00087277,  0.0008886 ,\n",
       "         0.0008876 ,  0.0033533 ,  0.00258641,  0.00529434,  0.00338247]),\n",
       " 'std_train_score': array([ 0.00112852,  0.00112837,  0.00123615,  0.00123616,  0.0017905 ,\n",
       "         0.00179005,  0.00248164,  0.00237749,  0.00262388,  0.00247418])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402575757209\n",
      "{'solver': 'saga', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time:512\n",
      "Train Accuary: 83.53%\n",
      "Train log_loss:  0.388722417524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/project_2/models/Onehot_A/LR_C0.1_A_cat.sklearn']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "\n",
    "c=0.1\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_hour')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4042898, 38), (4042898,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "solvers = ['sag','saga']\n",
    "Cs = [ 0.01, 0.1, 1, 10, 100, ]\n",
    "tuned_parameters = dict(solver = solvers, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=3, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  33.70156749,  207.99539844,  183.90029987,  207.61317428,\n",
       "         201.66621614,  207.55812836,  198.12250717,  208.25508253,\n",
       "         107.69542424,   49.87002707]),\n",
       " 'mean_score_time': array([ 0.54462361,  0.55181026,  0.54617755,  0.55055491,  0.55153791,\n",
       "         0.55444105,  0.55654796,  0.54728111,  0.54550425,  0.54442239]),\n",
       " 'mean_test_score': array([-0.45661863, -0.45661903, -0.45662441, -0.45668707, -0.45720272,\n",
       "        -0.45810941, -0.45915906, -0.46043816, -0.4595911 , -0.46073245]),\n",
       " 'mean_train_score': array([-0.45503394, -0.45503394, -0.45503393, -0.45503393, -0.45503393,\n",
       "        -0.45503393, -0.45503393, -0.45503393, -0.45503393, -0.45503393]),\n",
       " 'param_C': masked_array(data = [0.01 0.01 0.1 0.1 1 1 10 10 100 100],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_solver': masked_array(data = ['sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 0.01, 'solver': 'sag'},\n",
       "  {'C': 0.01, 'solver': 'saga'},\n",
       "  {'C': 0.1, 'solver': 'sag'},\n",
       "  {'C': 0.1, 'solver': 'saga'},\n",
       "  {'C': 1, 'solver': 'sag'},\n",
       "  {'C': 1, 'solver': 'saga'},\n",
       "  {'C': 10, 'solver': 'sag'},\n",
       "  {'C': 10, 'solver': 'saga'},\n",
       "  {'C': 100, 'solver': 'sag'},\n",
       "  {'C': 100, 'solver': 'saga'}],\n",
       " 'rank_test_score': array([ 1,  2,  3,  4,  5,  6,  7,  9,  8, 10], dtype=int32),\n",
       " 'split0_test_score': array([-0.45589009, -0.45588999, -0.45589138, -0.45589128, -0.45589149,\n",
       "        -0.45589146, -0.45589152, -0.45589152, -0.45589149, -0.45589142]),\n",
       " 'split0_train_score': array([-0.45512848, -0.45512848, -0.45512847, -0.45512847, -0.45512847,\n",
       "        -0.45512847, -0.45512847, -0.45512847, -0.45512847, -0.45512847]),\n",
       " 'split1_test_score': array([-0.45740032, -0.45740174, -0.45741185, -0.45760005, -0.45914628,\n",
       "        -0.46186639, -0.46501519, -0.4688525 , -0.46631129, -0.46973556]),\n",
       " 'split1_train_score': array([-0.45488998, -0.45488998, -0.45488996, -0.45488996, -0.45488996,\n",
       "        -0.45488996, -0.45488996, -0.45488996, -0.45488996, -0.45488996]),\n",
       " 'split2_test_score': array([-0.45656548, -0.45656536, -0.45656998, -0.45656987, -0.4565704 ,\n",
       "        -0.45657038, -0.45657047, -0.45657047, -0.45657051, -0.45657035]),\n",
       " 'split2_train_score': array([-0.45508337, -0.45508337, -0.45508336, -0.45508336, -0.45508336,\n",
       "        -0.45508336, -0.45508336, -0.45508336, -0.45508336, -0.45508336]),\n",
       " 'std_fit_time': array([  1.90914745,   0.34787986,  13.52938982,   0.0927355 ,\n",
       "          0.47329044,   1.25327817,   0.3122925 ,   0.64082091,\n",
       "          5.17408112,   0.98749057]),\n",
       " 'std_score_time': array([ 0.00461545,  0.0059997 ,  0.00720013,  0.00439669,  0.00224052,\n",
       "         0.00412517,  0.00258654,  0.00540779,  0.0062575 ,  0.00580852]),\n",
       " 'std_test_score': array([ 0.00061769,  0.00061833,  0.00062192,  0.00070251,  0.00140197,\n",
       "         0.00267101,  0.00415017,  0.00595629,  0.00475998,  0.00637219]),\n",
       " 'std_train_score': array([ 0.00010345,  0.00010345,  0.00010345,  0.00010345,  0.00010345,\n",
       "         0.00010345,  0.00010345,  0.00010345,  0.00010345,  0.00010345])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.456618630337\n",
      "{'solver': 'sag', 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:57\n",
      "Train Accuary: 83.00%\n",
      "Train log_loss:  0.455267064789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/project_2/models/Onehot_A/LR_C0.01_A_hour.sklearn']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "\n",
    "c=0.01\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T13:37:44.806898Z",
     "start_time": "2018-07-07T13:37:44.686975Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_cat_xgb')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4042898, 51200), (4042898,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "solvers = ['sag','saga']\n",
    "Cs = [ 0.01, 0.1, 1, 10, 100, ]\n",
    "tuned_parameters = dict(solver = solvers, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=3, scoring='neg_log_loss', n_jobs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:32\n",
      "Train Accuary: 83.00%\n",
      "Train log_loss:  0.453926167587\n"
     ]
    }
   ],
   "source": [
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "\n",
    "c=0.01\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-07T13:37:44.806898Z",
     "start_time": "2018-07-07T13:37:44.686975Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_B')\n",
    "PARAMS = params('B_cat_xgb')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#导入数据\n",
    "\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "solvers = ['sag','saga']\n",
    "Cs = [ 0.01, 0.1, 1, 10, 100, ]\n",
    "tuned_parameters = dict(solver = solvers, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=3, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:32\n",
      "Train Accuary: 83.00%\n",
      "Train log_loss:  0.453926167587\n"
     ]
    }
   ],
   "source": [
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "\n",
    "c=0.01\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_B')\n",
    "PARAMS = params('B_cat')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4042898, 901808), (4042898,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "solvers = ['sag','saga']\n",
    "Cs = [ 0.01, 0.1, 1, 10, 100, ]\n",
    "tuned_parameters = dict(solver = solvers, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=3, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  40.3663396 ,   49.49943328,   49.84781265,   80.88739292,\n",
       "         199.45493261,  206.05165696,  197.66245071,  202.43555601,\n",
       "         196.41139174,  202.96178778]),\n",
       " 'mean_score_time': array([ 0.52589401,  0.52809691,  0.52170324,  0.52200667,  0.52575588,\n",
       "         0.52752177,  0.52544602,  0.52752463,  0.52813784,  0.52762826]),\n",
       " 'mean_test_score': array([-0.45512197, -0.45512413, -0.45423192, -0.45423608, -0.45474148,\n",
       "        -0.45464744, -0.4651223 , -0.45945798, -0.47023533, -0.46088521]),\n",
       " 'mean_train_score': array([-0.45434805, -0.45434948, -0.44931142, -0.44931736, -0.42797456,\n",
       "        -0.42882026, -0.40228668, -0.41147112, -0.39782552, -0.40888018]),\n",
       " 'param_C': masked_array(data = [0.01 0.01 0.1 0.1 1 1 10 10 100 100],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_solver': masked_array(data = ['sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 0.01, 'solver': 'sag'},\n",
       "  {'C': 0.01, 'solver': 'saga'},\n",
       "  {'C': 0.1, 'solver': 'sag'},\n",
       "  {'C': 0.1, 'solver': 'saga'},\n",
       "  {'C': 1, 'solver': 'sag'},\n",
       "  {'C': 1, 'solver': 'saga'},\n",
       "  {'C': 10, 'solver': 'sag'},\n",
       "  {'C': 10, 'solver': 'saga'},\n",
       "  {'C': 100, 'solver': 'sag'},\n",
       "  {'C': 100, 'solver': 'saga'}],\n",
       " 'rank_test_score': array([ 5,  6,  1,  2,  4,  3,  9,  7, 10,  8], dtype=int32),\n",
       " 'split0_test_score': array([-0.4551885 , -0.45519062, -0.45442818, -0.45443358, -0.45528979,\n",
       "        -0.45519329, -0.46593981, -0.4602139 , -0.47108886, -0.46166536]),\n",
       " 'split0_train_score': array([-0.4543789 , -0.45438009, -0.44927172, -0.44927552, -0.42778148,\n",
       "        -0.42862673, -0.40208308, -0.4112517 , -0.3976246 , -0.40866318]),\n",
       " 'split1_test_score': array([-0.45496436, -0.45497122, -0.45385245, -0.45386021, -0.45387049,\n",
       "        -0.45378879, -0.46356653, -0.45820174, -0.46843986, -0.45955978]),\n",
       " 'split1_train_score': array([-0.45442757, -0.45442897, -0.44941956, -0.44942871, -0.42792603,\n",
       "        -0.42878254, -0.40197099, -0.41125497, -0.39746447, -0.40863597]),\n",
       " 'split2_test_score': array([-0.45521306, -0.45521053, -0.45441513, -0.45441444, -0.45506416,\n",
       "        -0.45496025, -0.46586055, -0.45995829, -0.47117727, -0.46143048]),\n",
       " 'split2_train_score': array([-0.45423768, -0.45423937, -0.44924299, -0.44924784, -0.42821618,\n",
       "        -0.4290515 , -0.40280596, -0.41190668, -0.39838748, -0.40934139]),\n",
       " 'std_fit_time': array([ 0.87705425,  2.49570557,  0.92799834,  5.48407124,  1.8137317 ,\n",
       "         0.33904034,  1.38526102,  0.2506167 ,  0.24011846,  0.49634828]),\n",
       " 'std_score_time': array([ 0.00560546,  0.00540746,  0.00172702,  0.00162453,  0.00171734,\n",
       "         0.00138979,  0.00132659,  0.00110607,  0.00098286,  0.00152952]),\n",
       " 'std_test_score': array([ 0.0001119 ,  0.00010842,  0.00026838,  0.00026589,  0.00062274,\n",
       "         0.00061457,  0.00110057,  0.0008944 ,  0.0012701 ,  0.00094211]),\n",
       " 'std_train_score': array([  8.05349814e-05,   8.03747722e-05,   7.73588210e-05,\n",
       "          7.95478381e-05,   1.80754396e-04,   1.75450195e-04,\n",
       "          3.70028758e-04,   3.07994241e-04,   4.02708212e-04,\n",
       "          3.26313190e-04])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454231915964\n",
      "{'solver': 'sag', 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:124\n",
      "Train Accuary: 83.02%\n",
      "Train log_loss:  0.449215597138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/project_2/models/Onehot_B/LR_C0.1_B_cat.sklearn']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "\n",
    "c=0.1\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_his')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4042898, 30), (4042898,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要调优的参数\n",
    "# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）\n",
    "#tuned_parameters = {'penalty':['l1','l2'],\n",
    "#                   'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "#                   }\n",
    "solvers = ['sag','saga']\n",
    "Cs = [ 0.01, 0.1, 1, 10, 100, ]\n",
    "tuned_parameters = dict(solver = solvers, C = Cs)\n",
    "\n",
    "lr_penalty= LogisticRegression()\n",
    "grid= GridSearchCV(lr_penalty, tuned_parameters,cv=3, scoring='neg_log_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 20.17629027,  28.43019478,  26.59142311,  26.69366582,\n",
       "         40.89491367,  27.82930295,  56.68577949,  29.24172815,\n",
       "         57.9981335 ,  28.83819652]),\n",
       " 'mean_score_time': array([ 0.52473609,  0.5248847 ,  0.52490401,  0.52642624,  0.52567863,\n",
       "         0.53004837,  0.52974876,  0.53003057,  0.52338767,  0.52351912]),\n",
       " 'mean_test_score': array([-0.45439099, -0.45439104, -0.45443027, -0.45443022, -0.4544359 ,\n",
       "        -0.45443588, -0.45443643, -0.45443644, -0.45443649, -0.45443651]),\n",
       " 'mean_train_score': array([-0.45384646, -0.45384646, -0.45383968, -0.45383968, -0.4538396 ,\n",
       "        -0.4538396 , -0.4538396 , -0.4538396 , -0.4538396 , -0.4538396 ]),\n",
       " 'param_C': masked_array(data = [0.01 0.01 0.1 0.1 1 1 10 10 100 100],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_solver': masked_array(data = ['sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga' 'sag' 'saga'],\n",
       "              mask = [False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'C': 0.01, 'solver': 'sag'},\n",
       "  {'C': 0.01, 'solver': 'saga'},\n",
       "  {'C': 0.1, 'solver': 'sag'},\n",
       "  {'C': 0.1, 'solver': 'saga'},\n",
       "  {'C': 1, 'solver': 'sag'},\n",
       "  {'C': 1, 'solver': 'saga'},\n",
       "  {'C': 10, 'solver': 'sag'},\n",
       "  {'C': 10, 'solver': 'saga'},\n",
       "  {'C': 100, 'solver': 'sag'},\n",
       "  {'C': 100, 'solver': 'saga'}],\n",
       " 'rank_test_score': array([ 1,  2,  4,  3,  6,  5,  7,  8,  9, 10], dtype=int32),\n",
       " 'split0_test_score': array([-0.4552681 , -0.4552682 , -0.45536011, -0.4553602 , -0.45537221,\n",
       "        -0.45537226, -0.45537347, -0.45537354, -0.45537353, -0.45537367]),\n",
       " 'split0_train_score': array([-0.45339165, -0.45339165, -0.45338514, -0.45338514, -0.45338506,\n",
       "        -0.45338506, -0.45338506, -0.45338506, -0.45338506, -0.45338506]),\n",
       " 'split1_test_score': array([-0.45356359, -0.4535636 , -0.45357106, -0.45357086, -0.45357327,\n",
       "        -0.45357316, -0.45357341, -0.4535734 , -0.45357344, -0.45357343]),\n",
       " 'split1_train_score': array([-0.45423797, -0.45423797, -0.4542299 , -0.4542299 , -0.4542298 ,\n",
       "        -0.4542298 , -0.4542298 , -0.4542298 , -0.4542298 , -0.4542298 ]),\n",
       " 'split2_test_score': array([-0.45434128, -0.45434131, -0.45435964, -0.45435961, -0.45436223,\n",
       "        -0.45436224, -0.45436241, -0.45436238, -0.45436251, -0.45436242]),\n",
       " 'split2_train_score': array([-0.45390976, -0.45390976, -0.453904  , -0.453904  , -0.45390394,\n",
       "        -0.45390394, -0.45390394, -0.45390394, -0.45390394, -0.45390394]),\n",
       " 'std_fit_time': array([ 0.59718061,  1.36707072,  0.43578968,  0.23867593,  1.71494933,\n",
       "         1.03431534,  4.11240928,  0.60303108,  2.43939846,  1.15564931]),\n",
       " 'std_score_time': array([ 0.00500021,  0.00421357,  0.0037625 ,  0.00415175,  0.0030972 ,\n",
       "         0.00738425,  0.00682529,  0.00819354,  0.00427859,  0.00448595]),\n",
       " 'std_test_score': array([ 0.00069675,  0.00069679,  0.00073208,  0.0007322 ,  0.00073626,\n",
       "         0.00073632,  0.00073673,  0.00073677,  0.00073674,  0.00073681]),\n",
       " 'std_train_score': array([ 0.0003484 ,  0.0003484 ,  0.00034786,  0.00034786,  0.00034785,\n",
       "         0.00034785,  0.00034785,  0.00034785,  0.00034785,  0.00034785])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.454390991972\n",
      "{'solver': 'sag', 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(-grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:32\n",
      "Train Accuary: 83.00%\n",
      "Train log_loss:  0.453926167587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/project_2/models/Onehot_A/LR_C0.01_A_his.sklearn']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "\n",
    "c=0.01\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 结论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total shape:  (4042898, 645182)  |  (1, 4042898)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = MergeNpz(output_path, file_name, data_begins, threshold,)\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "\n",
    "c=\n",
    "\n",
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=c, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}_{1}.sklearn'.format(c,onehot_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-08T13:48:54.372832Z",
     "start_time": "2018-02-08T13:48:54.361825Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhou/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time:549\n",
      "Train Accuary: 83.77%\n",
      "Train log_loss:  0.3737715081\n"
     ]
    }
   ],
   "source": [
    "#导入模型\n",
    "\n",
    "lr= LogisticRegression(multi_class='ovr', penalty='l2', solver='sag', C=1, n_jobs=-1)\n",
    "\n",
    "#开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "lr.fit(X_train, y_train, )\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "#保存模型\n",
    "#joblib.dump(lr, model_path+'LR_sklearn.model')\n",
    "\n",
    "#进行评价\n",
    "train_preds = lr.predict_proba(X_train)[:,1]\n",
    "train_predictions = np.around(train_preds)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T03:57:38.974458Z",
     "start_time": "2018-02-23T03:57:38.965450Z"
    }
   },
   "source": [
    "# 'C': 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/project_2/models/Onehot_A/LR_C0.1.sklearn_more10__']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0.1\n",
    "#保存模型\n",
    "joblib.dump(lr, model_path+'LR_C{0}.sklearn_more{1}__'.format(c,threshold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_model = joblib.load(model_path+model_path+'LR_C{0}.sklearn'.format(c))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "773px",
    "left": "0px",
    "right": "658.92px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
